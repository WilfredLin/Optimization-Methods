import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize classifiers
log_reg = LogisticRegression(random_state=42)
decision_tree = DecisionTreeClassifier(random_state=42)
random_forest = RandomForestClassifier(random_state=42)

# Define the parameter grids for hyperparameter optimization
param_grid_log_reg = {
    'penalty': ['l1', 'l2'],
    'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear']  # 'liblinear' is used for L1 regularization
}

param_grid_decision_tree = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

param_grid_random_forest = {
    'n_estimators': [10, 50, 100],
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

# Perform Grid Search with Cross-Validation for each classifier
grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5, scoring='accuracy')
grid_search_decision_tree = GridSearchCV(decision_tree, param_grid_decision_tree, cv=5, scoring='accuracy')
grid_search_random_forest = GridSearchCV(random_forest, param_grid_random_forest, cv=5, scoring='accuracy')

grid_search_log_reg.fit(X_train, y_train)
grid_search_decision_tree.fit(X_train, y_train)
grid_search_random_forest.fit(X_train, y_train)

# Print the best parameters and the best scores for each classifier
print("Logistic Regression - Best Hyperparameters:", grid_search_log_reg.best_params_)
print("Logistic Regression - Best Cross-Validation Score:", grid_search_log_reg.best_score_)

print("Decision Tree - Best Hyperparameters:", grid_search_decision_tree.best_params_)
print("Decision Tree - Best Cross-Validation Score:", grid_search_decision_tree.best_score_)

print("Random Forest - Best Hyperparameters:", grid_search_random_forest.best_params_)
print("Random Forest - Best Cross-Validation Score:", grid_search_random_forest.best_score_)

# Evaluate the best models on the test set
best_model_log_reg = grid_search_log_reg.best_estimator_
best_model_decision_tree = grid_search_decision_tree.best_estimator_
best_model_random_forest = grid_search_random_forest.best_estimator_

y_pred_log_reg = best_model_log_reg.predict(X_test)
y_pred_decision_tree = best_model_decision_tree.predict(X_test)
y_pred_random_forest = best_model_random_forest.predict(X_test)

test_accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
test_accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)
test_accuracy_random_forest = accuracy_score(y
